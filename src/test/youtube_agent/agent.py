from google.adk.agents import LlmAgent, BaseAgent, SequentialAgent
from google.adk.tools.mcp_tool.mcp_toolset import MCPToolset, StdioServerParameters
# from google.adk.tools import SseServerParams
from google.adk.events import Event
from google.genai import types
import json
import os
from apify_client import ApifyClient
# Get tools synchronously

query_agent = LlmAgent(
    model="gemini-2.0-flash",
    name="search_agent",
    instruction="""You are a youtube search query generator agent. 
    You will be given a topic user is interested in and you should come up with an array of 2 relevant search queries to find the most relevant videos.
    You should be in json format.""",
    output_key="search_query"
)

class YoutubeSearchAgent(BaseAgent): # Example custom agent
    name: str = "Youtube search agent"
    description: str = "Searches youtube for videos using Apify scraper."
    # ... internal logic ...
    async def _run_async_impl(self, ctx): # Simplified run logic
        # Initialize Apify client
        client = ApifyClient("apifu_token_here")
        
        # Get search queries from context
        search_queries = ctx.session.state.get("search_query", ["default search query"])
        print(f"Raw search queries: {search_queries}")
        
        # Handle the JSON string with markdown code block
        if isinstance(search_queries, str):
            try:
                # Remove markdown code block formatting
                search_queries = search_queries.replace('\n', '').replace('```json', '').replace('```', '').strip()
                search_queries = json.loads(search_queries)
            except json.JSONDecodeError as e:
                print(f"JSON decode error: {e}")
                search_queries = [search_queries]  # If not valid JSON, treat as single query
        elif not isinstance(search_queries, list):
            search_queries = [str(search_queries)]  # Convert to list if single item

        print(f"Processed search queries: {search_queries}")
        video_data = []

        for query in search_queries:
            # Run the YouTube scraper
            run_input = {
                "downloadSubtitles": False,
                "hasCC": False,
                "hasLocation": False,
                "hasSubtitles": False,
                "is360": False,
                "is3D": False,
                "is4K": False,
                "isBought": False,
                "isHD": False,
                "isHDR": False,
                "isLive": False,
                "isVR180": False,
                "maxResultStreams": 0,
                "maxResults": 1,
                "maxResultsShorts": 0,
                "preferAutoGeneratedSubtitles": False,
                "saveSubsToKVS": False,
                "searchQueries": [
                    query
                ]
            }
            
            run = client.actor("streamers/youtube-scraper").call(run_input=run_input)
            
            # Get the results
            for item in client.dataset(run["defaultDatasetId"]).iterate_items():
                from youtube_transcript_api import YouTubeTranscriptApi
                transcript = YouTubeTranscriptApi().fetch(item.get('url').split('=')[1])
                print(transcript)
                video_data.append({
                    'title': item.get('title'),
                    'description': item.get('description'),
                    'url': item.get('url'),
                    'views': item.get('viewCount'),
                    'likes': item.get('likeCount'),
                    'uploadDate': item.get('uploadDate'),
                    'transcript': transcript
                })

        yield Event(author=self.name, content=types.Content(parts=[types.Part(text=json.dumps(video_data))]))

search_agent = YoutubeSearchAgent()

youtube_agent = SequentialAgent(
    name="youtube_query_search_agent",
    description="Expands search queries and scrapes youtube for videos using Apify scraper.",
    sub_agents=[
        query_agent,
        search_agent
    ]
)

supabase_agent = LlmAgent(
    model="gemini-2.0-flash",  # Specifies the LLM model to use
    name="supabase_agent",            # A name for this specific agent
    instruction="""You are a database agent, you have access to two tables: posts and strategies.
      Any requests related to posts should be answered by querying the posts table, any requests related to strategies should be answered by querying the strategies table.
      The posts and strategies table are related by the strategy_name column.
      """, # The agent's primary instruction
    tools=[
        MCPToolset(
            connection_params=StdioServerParameters(
                command="npx",
                args=[
                    "-y",
                    "@supabase/mcp-server-supabase@latest",
                    "--access-token",
                    "your_supabase_access_token_here",
                    "--project-ref",
                    "your_supabase_project_ref_here"
                ]
            )
            # tool_filter=['load_web_page'] # Optional: ensure only specific tools are loaded
        )
    ],             # The list of tools available to the agent
)

# Create the root agent with the tools
root_agent = LlmAgent(
    model="gemini-2.0-flash",  # Specifies the LLM model to use
    name="youtube_analyzer",            # A name for this specific agent
    instruction="""You are a content strategy agent.
    You should help the user either come up with a new content strategy or optimize their existing content strategy.
    you should understand the user's needs and ask the user for a topic they are interested in
     - use the youtube_agent to find sample content on youtube with that topic
     - use the supabase_agent to get information about user's current content strategy and previous posts
""", # The agent's primary instruction
    sub_agents=[
        youtube_agent,
        supabase_agent
    ],             # The list of tools available to the agent
)
