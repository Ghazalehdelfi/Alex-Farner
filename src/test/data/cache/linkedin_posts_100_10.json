{"timestamp": 1748808599.866978, "content": [{"content": "We are proud to celebrate Tastemade Japan (an affiliate of Mitsui) for winning the Grand Prix in the Film Advertising (Short Film) category and the Best Partner Award at the prestigious JAA Advertising Awards.\n\nThe winning entry is a set of three short films showcasing Hokkaido\u2019s finest seafood in unexpected ways \u2013 stimulating the imagination of taste through sight.\n\nA major award in the Japanese advertising world, the JAA Advertising Awards are unique in that it is judged by consumers rather than industry professionals, recognising content that resonates deeply with everyday audiences.\n\nThis win underscores Tastemade Japan\u2019s creative excellence, recognising the creative team\u2019s ability to deliver engaging content that highlights the value of premium food products while bringing them to life through masterful storytelling.\n\nWatch the English version of the award-winning films here!\n\n\nhashtag\n#Mitsui \nhashtag\n#TastemadeJapan \nhashtag\n#Hokkaido \nhashtag\n#JAA \nhashtag\n#JAAAdvertisingAwards \nhashtag\n#FoodInnovation", "likes": "19,995", "comments": "207 comments", "timestamp": "2025-06-01T16:08:54.108346", "total_engagement": 20202}, {"content": "I am alarmed by the proposed cuts to U.S. funding for basic research, and the impact this would have for U.S. competitiveness in AI and other areas. Funding research that is openly shared benefits the whole world, but the nation it benefits most is the one where the research is done.\n\nIf not for funding for my early work in deep learning from the National Science Foundation (NSF) and Defense Advanced Research Projects Agency (DARPA), which disburse a good deal of U.S. research funding, I would not have discovered lessons about scaling that led me to pitch starting Google Brain to scale up deep learning. I am worried that cuts to funding for basic science will lead the U.S. \u2014 and also the world \u2014 to miss out on the next set of ideas.\n\nIn fact, such funding benefits the U.S. more than any other nation. Scientific research brings the greatest benefit to the country where the work happens because (i) the new knowledge diffuses fastest within that country, and (ii) the process of doing research creates new talent for that nation.\n\nWhy does most innovation in generative AI still happen in Silicon Valley? Because two teams based in this area \u2014 Google Brain, which invented the transformer network, and OpenAI, which scaled it up \u2014 did a lot of the early work. Subsequently, team members moved to other nearby businesses, started competitors, or worked with local universities. Further, local social networks rapidly diffused the knowledge through casual coffee meetings, local conferences, and even children\u2019s play dates, where parents of like-aged kids meet and discuss technical ideas. In this way, the knowledge spread faster within Silicon Valley than to other geographies.\n\nIn a similar vein, research done in the U.S. diffuses to others in the U.S. much faster than to other geographic areas. This is particularly true when the research is openly shared through papers and/or open source: If researchers have permission to talk about an idea, they can share much more information, such as tips and tricks for how to really make an algorithm work, more quickly. It also lets others figure out faster who can answer their questions. Diffusion of knowledge created in academic environments is especially fast. Academia tends to be completely open, and students and professors, unlike employees of many companies, have full permission to talk about their work.\n\nThus funding basic research in the U.S. benefits the U.S. most, and also benefits our allies. It is true that openness benefits our adversaries, too. But as a subcommittee of the U.S. House of Representatives committee on science, space, and technology points out, \u201c... open sharing of fundamental research is [not] without risk. Rather, ... openness in research is so important to competitiveness and security that it warrants the risk that adversaries may benefit from scientific openness as well.\u201d\n\n[Truncated due to length limit. Full post: https://lnkd.in/gQfYfxAF ]", "likes": "3,769", "comments": "157 comments", "timestamp": "2025-06-01T16:09:07.591306", "total_engagement": 3926}, {"content": "Learn to build conversational AI voice agents in \"Building AI Voice Agents for Production\", created in collaboration with LiveKit and RealAvatar, and taught by Russ d'Sa (Co-founder & CEO of LiveKit), Shayne Parmelee (Developer Advocate, LiveKit), and Nedelina Teneva, PhD (Head of AI at RealAvatar, an AI Fund portfolio company).\n\nVoice agents combine speech and reasoning capabilities to enable real-time conversations. They're already being used to support customer service, to improve accessibility in healthcare, for entertainment applications, and for talk therapy.\n\nIn this course, you\u2019ll learn to build voice agents that listen, reason, and respond naturally. You\u2019ll follow the architecture used to create the \"AI Andrew\" Avatar, a collaborative project between DeepLearning.AI and RealAvatar that responds to users in what sounds like my voice. You\u2019ll build a voice agent from scratch and deploy it to the cloud, enabling support for many simultaneous users.\n\nWhat you\u2019ll learn:\n- Understand the fundamentals of voice agents, including key components like speech-to-text (STT), text-to-speech (TTS), and LLMs, and how latency is introduced at each layer.\n- Explore voice agent architectures and the trade-offs between modular pipelines and speech-to-speech APIs.\n- Explore how platforms like LiveKit mitigate latency issues with optimized networking infrastructure and low-latency communication protocols.\n- Learn how to connect client devices to voice agents using WebRTC\u2014and why it outperforms HTTP and WebSocket for low-latency audio streaming.\n- Incorporate voice activity detection (VAD), end-of-turn detection, and context management to detect turns, handle interruptions, and manage conversational flow.\n- Understand the trade-offs between latency, quality, and cost in an example in which you build a voice agent and change its voice.\n- Equip your agent with metrics to measure latency at each stage of the voice pipeline and learn the key levers you can pull to make your agent faster and more responsive.\n\nThe voice agents built in this course also incorporate voice technology from ElevenLabs, a supporting contributor to the project.\n\nBy the end of this course, you'll have learned the components of an AI voice agent pipeline, combined them into a system with low-latency communication, and deployed them on cloud infrastructure so it scales to many users.\n\nI\u2019m looking forward to seeing what voice agents you build from this course!\n\nPlease sign up here: https://lnkd.in/gEBXAGH8", "likes": "3,156", "comments": "151 comments", "timestamp": "2025-06-01T16:09:48.568207", "total_engagement": 3307}, {"content": "A Lovable Transformation\u00a0\u2764\ufe0f \n\nFrom 200 Python Servers to 10 Golang servers \ud83d\udd3b \n\nLovable is a leading AI company that helps teams build and ship products faster.\n\nTheir code was written in Python with around 42,000 lines of Python code. \n\nAs they started facing increasing demands from high-concurrency workloads. Python\u2019s limitations began to show.\n\nPython is a great language, but not meant for building high-concurrency parallel\u00a0workload servers.\n\nIn fact, JetBrains\u2019 latest developer survey reveals that more than 38% of Python developers use it to build API services.\n\nThe Solution: \nLovable rewrote their entire 42,000-line Python codebase in Golang.\n\nThe results: \n-\u00a0Deployment time slashed\u00a0from 15 minutes to just 3.\n-\u00a0Request speed improved\u00a0by 12%, enhancing user experience.\n- Most important:\u00a0Server instance count dropped\u00a0from 200 to 10\n\nDrastically cutting overall infrastructure costs. \ud83d\ude80 \n\nAre you spending too much on your server infrastructure? \ud83d\udcb0 \n\nYou can consider\u00a0switching to Golang. \n\n--\nAt Scalent, we specialize in developing secure, scalable, and high-performance applications with Golang.", "likes": "2,598", "comments": "118 comments", "timestamp": "2025-06-01T16:09:07.579346", "total_engagement": 2716}, {"content": "Can it really be a coincidence? Find out more at Goldhub.com", "likes": "2,188", "comments": "33 comments", "timestamp": "2025-06-01T16:09:14.556963", "total_engagement": 2221}, {"content": "If I had to learn AI PM again, I would start here (the extended edition):\n\n\ud835\udfcf. \ud835\udc01\ud835\udc1a\ud835\udc2c\ud835\udc22\ud835\udc1c \ud835\udc02\ud835\udc28\ud835\udc27\ud835\udc1c\ud835\udc1e\ud835\udc29\ud835\udc2d\ud835\udc2c\n\nStart with what an AI PM is: https://bit.ly/whatisaipm\n\nNext, for most PMs, it makes no sense to dive deep into statistics, Python, or loss functions.\n\nInstead, read about Transformers, and LLMs: https://bit.ly/3EZtCLs\n\n\ud835\udfd0. \ud835\udc0f\ud835\udc2b\ud835\udc28\ud835\udc26\ud835\udc29\ud835\udc2d \ud835\udc04\ud835\udc27\ud835\udc20\ud835\udc22\ud835\udc27\ud835\udc1e\ud835\udc1e\ud835\udc2b\ud835\udc22\ud835\udc27\ud835\udc20\n\nFree resources:\n\ud83d\udd17 GPT-4.1 Prompting Guide\n\ud83d\udd17 Anthropic Prompt Engineering\n\ud83d\udd17 Prompt Engineering by Google\n\ud83d\udd17 System Prompt Analysis for Claude 4\n\ud83d\udd17 Anthropic Prompt Generator\n\ud83d\udd17 Anthropic Prompt Library\n\ud83d\udd17 Prompt Engineering Course By Anthropic\n\nAll links: https://bit.ly/pcprompts\n\n\ud835\udfd1. \ud835\udc05\ud835\udc22\ud835\udc27\ud835\udc1e-\ud835\udc13\ud835\udc2e\ud835\udc27\ud835\udc22\ud835\udc27\ud835\udc20\n\nLearn by doing. No coding: \n\ud83d\udd17 OpenAI Platform (start here)\n\ud83d\udd17 Hugging Face AutoTrain (best for other models)\n\ud83d\udd17 LaMA-Factory (fine-tune open-source LLMs)\n\nAll links: https://bit.ly/pcfinetune\n\n\ud835\udfd2. \ud835\udc11\ud835\udc00\ud835\udc06 (\ud835\udc11\ud835\udc1e\ud835\udc2d\ud835\udc2b\ud835\udc22\ud835\udc1e\ud835\udc2f\ud835\udc1a\ud835\udc25-\ud835\udc00\ud835\udc2e\ud835\udc20\ud835\udc26\ud835\udc1e\ud835\udc27\ud835\udc2d\ud835\udc1e\ud835\udc1d \ud835\udc06\ud835\udc1e\ud835\udc27\ud835\udc1e\ud835\udc2b\ud835\udc1a\ud835\udc2d\ud835\udc22\ud835\udc28\ud835\udc27)\n\nRAG, by definition, requires a data source + LLM. But there are dozens of possible architectures.\n\nI recommend a simple step-by-step exercise to build a RAG chatbot in practice. No coding: https://lnkd.in/dew--RqD\n\nMore: https://bit.ly/pcrag\n\n\ud835\udfd3. \ud835\udc00\ud835\udc08 \ud835\udc00\ud835\udc20\ud835\udc1e\ud835\udc27\ud835\udc2d\ud835\udc2c & \ud835\udc00\ud835\udc20\ud835\udc1e\ud835\udc27\ud835\udc2d\ud835\udc22\ud835\udc1c \ud835\udc16\ud835\udc28\ud835\udc2b\ud835\udc24\ud835\udc1f\ud835\udc25\ud835\udc28\ud835\udc30\ud835\udc2c\n\nMy favorite tool, by far, is n8n. You can host a free version locally or in the cloud.\n\nStart with those guides:\n\ud83d\udd17 MCP for PMs\n\ud83d\udd17 Automate Anything with n8n\n\ud83d\udd17 AI Agent Architectures\n\nMy favorite free resources:\n\ud83d\udd17 Google Agent Companion\n\ud83d\udd17 Anthropic Building Effective Agents\n\ud83d\udd17 IBM Agentic Process Automation\n\nAll links: https://bit.ly/pcaiagents\n\n\ud835\udfd4. \ud835\udc00\ud835\udc08 \ud835\udc0f\ud835\udc2b\ud835\udc28\ud835\udc2d\ud835\udc28\ud835\udc2d\ud835\udc32\ud835\udc29\ud835\udc22\ud835\udc27\ud835\udc20 & \ud835\udc00\ud835\udc08 \ud835\udc01\ud835\udc2e\ud835\udc22\ud835\udc25\ud835\udc1d\ud835\udc22\ud835\udc27\ud835\udc20\n\nMy default no-code tech stack: Lovable, Supabase, GitHub, Netlify, n8n, Stripe.\n\nFour practical tutorials:\n\ud83d\udd17 AI Prototyping\n\ud83d\udd17 How to Quickly Build SaaS Products With AI \n\ud83d\udd17 How to Build a Full-Stack App with Lovable\n\ud83d\udd17 No-Code B2C SaaS Template With Stripe Payments\n\nAll links: https://lnkd.in/du5TSFfd\n\n\ud835\udfd5. \ud835\udc05\ud835\udc28\ud835\udc2e\ud835\udc27\ud835\udc1d\ud835\udc1a\ud835\udc2d\ud835\udc22\ud835\udc28\ud835\udc27\ud835\udc1a\ud835\udc25 \ud835\udc0c\ud835\udc28\ud835\udc1d\ud835\udc1e\ud835\udc25\ud835\udc2c\n\nMy favorite models (May 29, 2025):\n- Claude for coding\n- ChatGPT for everything else\n\n\ud835\udfd6. \ud835\udc00\ud835\udc08 \ud835\udc04\ud835\udc2f\ud835\udc1a\ud835\udc25\ud835\udc2e\ud835\udc1a\ud835\udc2d\ud835\udc22\ud835\udc28\ud835\udc27 \ud835\udc12\ud835\udc32\ud835\udc2c\ud835\udc2d\ud835\udc1e\ud835\udc26\ud835\udc2c\n\nYou might have an advanced AI architecture. But does your product actually work?\n\nEvals are critical. And it's a task also for PMs! A free, detailed guide: https://lnkd.in/dHUFrkVs\n\n\ud835\udfd7. \ud835\udc0e\ud835\udc2d\ud835\udc21\ud835\udc1e\ud835\udc2b \ud835\udc11\ud835\udc1e\ud835\udc2c\ud835\udc28\ud835\udc2e\ud835\udc2b\ud835\udc1c\ud835\udc1e\ud835\udc2c\n\n\ud83d\udd17 A free PRD template\n\ud83d\udd17 Anthropic MCP Servers\n\ud83d\udd17 ChatLLM: All LLMs with just one $10/month subscription\n\ud83d\udd17 ...and more\n\nAll links: https://lnkd.in/dSA3JgFw\n\n---\n\nThe full AI PM learning guide: https://lnkd.in/dkmU7_gr\n\nHope that helps! \n\nWhat did I forget?\n\n---\n\nInterested in AI PM?\n\nI recommend the\u00a0AI PM Certification. I participated in this 6-week cohort last year. I loved networking and rolling up my sleeves.\n\nThe next session starts on July 13, 2025. \n\nA\u00a0$500 discount only for my community: https://bit.ly/aipmcohort", "likes": "1,620", "comments": "74 comments", "timestamp": "2025-06-01T16:08:57.456805", "total_engagement": 1694}, {"content": "Two tech giants. Two viral launches.\nOne melted. One mastered it.\n\nWhen ChatGPT launched image generation, the Ghibli trend took off like wildfire.\n700 million+ images in just a week.\nThe hype was beautiful\u2026 and brutal.\n\nServers strained. GPUs screamed.\nSam Altman literally said, \u201cOur GPUs are melting.\"\n\nThen came Google Veo 3.\nSame AI magic. Cinematic quality. Insane potential.\nBut instead of opening the floodgates, Google played it cool.\nLaunched selectively in the U.S., built curiosity, created FOMO.\n\nAnd now?\nVeo 3 has expanded to 71 countries, including NEPAL, SRI LANKA, and PAKISTAN. Still no INDIA.\n\nWhy?\nBecause when ChatGPT went viral with image generation, OpenAI underestimated India\u2019s demand.\n\nThe servers melted. The team wasn\u2019t ready.\nTurns out, India isn\u2019t just \u201ca market\u201d, it\u2019s the second-largest user base for AI tools. Looks like Google took notes.\n\nAs a consumer in India though\u2026 I am still refreshing that Veo 3 access page daily.\n\n\nhashtag\n#GoogleVeo3 \nhashtag\n#ChatGPT \nhashtag\n#AItools \nhashtag\n#LaunchStrategy", "likes": "1,341", "comments": "77 comments", "timestamp": "2025-06-01T16:09:40.796649", "total_engagement": 1418}, {"content": "Will \nhashtag\n#AI be a bloodbath for white-collar jobs? \nhashtag\n#Anthropic CEO Dario Amodei seems to think so\u2014he made headlines warning that AI could wipe out up to 50% of all entry-level white-collar roles within the next 5 years. While we can debate the exact figure, I won\u2019t quibble: a lot of work is about to be automated.\n\nAI isn\u2019t just a helper anymore\u2014it\u2019s becoming a full-blown replacement for the repetitive, digitized, \u201cthunking\u201d tasks that fill so many junior roles. If you\u2019re not paying attention, you\u2019re at risk of missing the train entirely.\n\nHere\u2019s the uncomfortable truth: What you see from AI today isn\u2019t the ceiling\u2014it\u2019s the floor. The cutting-edge research is far ahead of what\u2019s in your hands. Even the most notoriously janky AI products\u2014like \nhashtag\n#OpenAI\u2019s Operator or \nhashtag\n#Google\u2019s Project Mariner\u2014could get a massive capability boost almost overnight, just by cranking up the compute (and, with it, the costs). The real bottleneck? Companies and customers aren\u2019t ready to pay for what\u2019s already possible. We\u2019re stuck in an awkward moment where the tech is ready, but the market\u2014and the culture\u2014aren\u2019t.\n\nThat gap won\u2019t last forever. AI isn\u2019t some far-off fantasy\u2014it\u2019s the next wave of automation, and it\u2019s already reshaping industries. The problem isn\u2019t that AI is \u201ccoming for your job\u201d\u2014it\u2019s that the tasks we once thought were too complex to automate are suddenly on the table. Copying, pasting, filling out forms, writing first drafts of emails\u2014those are the tasks AI is best at. And that means the entry-level training grounds we\u2019ve relied on for generations\u2014where people cut their teeth and build their skills\u2014are vanishing fast. Where will the next generation of talent come from if we don\u2019t rethink our pipelines?\n\nLet\u2019s be clear: the next few years will be rough, especially for junior employees. AI is far less of a threat to those with industry experience, deep domain expertise, or strong networks. But if you\u2019re doing work that \u201canyone can do,\u201d AI will soon be able to do it too. I won\u2019t sugarcoat this, so let me say it again for the folks in the back:\n\n\u26a0\ufe0f If anyone can do it, AI will soon be able to do it too. \u26a0\ufe0f\n\nIf you\u2019re a student or just entering the workforce, now is the time to build relationships, seek out mentors, and cultivate a love of learning\u2014because the treadmill is real, and it\u2019s only speeding up. The future belongs to those who can adapt quickly and learn the new rules of new games.\n\nIf you\u2019re a leader, this is your moment to lead with compassion. Not everyone loves a constant challenge, and some implicit promises\u2014about stable career paths, about learning your trade and coasting\u2014are about to be broken. AI can empower us to aim higher, but only if we stay nimble. Your job is to build safe learning spaces, empower your teams to experiment with AI tools, and create clear pathways for growth beyond the tasks AI will automate.\n\nLet\u2019s not just brace for impact\u2014let\u2019s get ready to lead through it.", "likes": "950", "comments": "202 comments", "timestamp": "2025-06-01T16:08:50.856580", "total_engagement": 1152}, {"content": "Last week I finally gave Cursor a proper test run \u2026here\u2019s my verdict.\n\n\n\nThe goal was simple: guide the tool through prompts (with minimal hand-holding), refactor as little as possible, and only provide additional context or examples when needed. For this, I picked an easy React frontend project.\n\nThe outcome (in my humble opinion):\nGreat for small, straightforward tasks and a complete shit show once things get even slightly complex.\n\nKey takeaways:\n- After a couple of days, the model quality noticeably dropped. I assume they throttle premium model usage for cost reasons, which is fair, but the fallback model became unusable.\n- When Cursor starts producing crap, it\u2019s nearly impossible to course-correct. Asking it to review or fix its own logic just leads to other pile of nonsense, like unnecessary hooks, effects, layers of confusion.\n- Context retention is poor. Ten prompts in, it forgets earlier decisions - now placing components in a different folder, switching from a provider pattern to a direct fetch without reason. You\u2019ll find yourself repeating instructions constantly.\n- For anything beyond basic logic, it collapses. In one case, I snapped and rewrote the entire piece myself: ~30 lines of clear code vs. 200+ bloated lines from Cursor.\n\u2026and the list goes on.\n\nBottom line:\nI genuinely don\u2019t see how even small teams can rely on it without ending up in a mess. That said, I won\u2019t completely write it off. If I ever need a \u201cjunior\u201d to assist on low-complexity tasks, Cursor might be useful.\n\nNext up: Windsurf, you\u2019re on deck \ud83e\udd2a\ud83d\ude02", "likes": "572", "comments": "281 comments", "timestamp": "2025-06-01T16:09:04.165203", "total_engagement": 853}, {"content": "Some moments from the 1990s still stay with me, not because of nostalgia, but because of the mindset they revealed.\n\nThat\u2019s when I first understood that entrepreneurship isn\u2019t about scale, it\u2019s about attitude. The same mindset that drives startups and family-run businesses can also thrive inside the world\u2019s largest organizations, if you make space for it.\n\nAt Lenovo, with over 70,000 people across 180 markets, we\u2019ve built that space. We\u2019ve nurtured a culture where agility, ownership, and bold ideas can grow, at any level, in any role.\n\nHere are a few reflections from those early days and how we\u2019re keeping the entrepreneurial spirit alive at scale. \ud83d\udc47\ud83c\udffc", "likes": "753", "comments": "35 comments", "timestamp": "2025-06-01T16:09:07.553474", "total_engagement": 788}]}